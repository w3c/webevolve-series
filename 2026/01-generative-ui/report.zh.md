
---
# Generative UI专题交流会总结

- [一、活动介绍](#一活动介绍) 
- [二、开场讨论（胡春明、王佐）](#二开场讨论胡春明王佐)
- [三、产业实践分享](#三产业实践分享)
  - [陆沉（蚂蚁）](#1-陆沉蚂蚁)
  - [莫春辉（华为）](#2-莫春辉华为)
  - [祖明（百度）](#3-祖明百度)
- [开放讨论环节](#开放讨论环节)
  - [Q1：性能与加载速度](#q1-在ai聊天场景里大模型生成ui界面的加载速度还重要吗)
  - [Q2：标准合作与生态](#q2-如何通过标准合作优化平台与生态)
  - [Q3：UI组件](#q3-ui组件)
  - [Q4：Web子集](#q4-web子集)
  - [Q5：测试与验证](#q5-测试与验证)
- [结论与下一步计划](#结论与下一步计划)


## 一、活动介绍

随着大模型与生成式AI的快速发展，**生成式UI（Generative UI）**正成为业界高度关注的方向。在探索这一领域多种技术路径的同时，业界也面临着性能效率、安全风险、可扩展性、互操作性等一系列新的挑战。

为进一步探讨Generative UI在Web领域的发展趋势与标准化可能性，**W3C中国**于**2026年1月29日**召开专题线上研讨会，来自W3C会员单位的**50多位与会者**参与了本次交流。

---

## 二、开场讨论（胡春明、王佐）

本次会议由**W3C董事会成员、北京航空航天大学胡春明教授**与**华为菲尔兹实验室王佐博士**开场并分享观点。

**胡春明教授**指出，AI辅助软件开发在Web领域的关注重心正逐步转向**前端UI**。随着大模型与智能体（Agent）参与人机交互，UI正成为新的关键交互层。目前，MCP/Agent已广泛采用生成式UI，并通过**Markdown、HTML或其他DSL**表达交互需求。

围绕未来交互层的表达方式及其标准化空间，他提出了若干值得深入讨论的问题：

* 标准应在**Markdown之上扩展能力**，还是对**HTML进行适度简化**？
* 生成式UI如何在AI辅助下实现**生成与约束的平衡**？
* W3C在**HTML/CSS高性能子集、小程序形态、“元服务”**等方向的探索，与上述议题高度相关。

他还提到，**W3C顾问委员会会议（[AC 2026](https://www.w3.org/zh-hans/events/)）**将于**中国杭州**举办，若能在会前逐步形成相关共识，将有助于推动更深入的交流与讨论。

---

**王佐博士**从大模型兴起后Web入口和应用形态变化的角度，分享了对**“深层次UI（Deep UI）”**的观察与思考：

* **PC端**：用户仍主要通过浏览器与模型交互，模型借助Web内核和MCP操控网页；
* **移动端**：服务分发逐步由模型完成，传统App/小程序中的Web页面形态正迁移为**模型生成的UI**。

这类UI具备更高的生产效率与更强的实时个性化能力，将成为未来人机交互的重要界面。

![图示](img-1.png)

在生成式UI的技术演进上，他认为业界已从 Markdown承载，发展到基于模板的UI，再进一步迈向更细粒度、模型直接生成界面的表达方式。当前，各大模型和平台往往定义各自私有的 UI 技术栈，给跨端适配和服务接入带来较高成本。他据此提出，应探索是否存在一个模型友好、跨平台的通用标准语言，减少重复适配，并建议这一方向可纳入W3C相关标准化讨论之中。

![图示](img-2.png)

---

W3C团队成员、[Web & AI 兴趣组](https://www.w3.org/groups/ig/webai/)联系人**冉若曦**主持本次会议讨论。他指出，随着大模型和智能体技术的发展，UI正从静态设计和模板组合，转向按需生成、动态适配的形态。生成式UI往往由模型自主生成，这对Web架构、交互方式和标准体系提出了新的问题与机遇。W3C希望通过此次交流，了解业界的真实实践，探索相关技术是否以及如何纳入未来的Web标准讨论。

---

## 三、产业实践分享

多位来自产业的技术专家分享了各自对生成式UI的理解与实践经验。

### 1. 陆沉（蚂蚁）

📄 PPT：
[https://www.w3.org/2026/01/GenUI-China/Perspectives_of_Generative_UI_RH.pptx](https://www.w3.org/2026/01/GenUI-China/Perspectives_of_Generative_UI_RH.pptx)

结合蚂蚁与业界实践，陆沉分享了对生成式UI的观察与思考：

* 随着大模型代码能力和Coding Agent的快速进化，业界对使用大模型生成Web页面和应用的信心显著增强，生成式UI正逐步成为关注焦点。
* 生成完整HTML的生成式UI路线正与AI Coding的边界发生重叠，引发对生成式UI定义与讨论重点的再思考。

他系统分析了三条技术路径：Markdown、DSL和HTML直出，并指出当前业界对HTML直出和DSL路线的兴趣明显上升。HTML直出具备极高的表达上限，但在安全、性能和基础设施成本方面挑战巨大；基于DSL的方案则通过组件化和受控渲染，在安全性、性能和跨端一致性方面更具优势，但由于各厂商可低成本自建，生态呈现高度割裂。

基于此，陆沉建议标准化工作应聚焦于三个方向：

* 探索模型友好的轻量级Web子集以提升安全性
* 研究更优的沙箱与隔离机制
* 推动跨厂商通用的生成式UI中间协议，为未来生态协同奠定基础


---

### 2. 莫春辉（华为）

📄 PPT：
[https://www.w3.org/2026/01/GenUI-China/Generative_UI_Technology_Insights_MCH.pptx](https://www.w3.org/2026/01/GenUI-China/Generative_UI_Technology_Insights_MCH.pptx)

从工程视角系统分析了生成式 UI（Generative UI）的技术本质与落地路径。他指出，生成式UI的核心不在于A 驱动模板选择，而在于“实时生成（Real-time Generation）”能力：模型需在运行时基于用户意图与上下文动态生成页面结构、组件类型、布局方式与交互逻辑。当前多数实践仍属于设计态预设UI，本质是模板编排系统。AI仅参与参数填充与决策辅助，场景覆盖率受限，难以支撑长尾需求。

围绕企业实践，他提出“场景覆盖率”作为衡量生成能力的关键指标：模板化方案的覆盖范围受模板规模制约，而真正的生成式UI理论上可实现全场景适配。在技术演进上，生成式UI将经历模板阶段、原子化组件动态组装阶段，最终迈向完全生成阶段，对运行时环境与标准化能力提出更高要求。

在实现层面，他比较了JSON与XML等DSL的适配性，指出XML在流式输出与不完整结构下更利于前端解析与实时渲染；同时强调需要统一渲染架构以支持 Web与Native多端一致性，并通过安全护栏机制确保生成结果可控。针对多页面生成带来的体验割裂问题，他提出“生成式小程序”思路，以AI统一调度多页面逻辑，支撑复杂业务闭环。他强调生成式 UI 必须支持企业自有组件接入，并允许文本、结构化UI与DSL的混合输出，才能真正落地。

并提出下一步的工作重点包括： 
* 探索浏览器内核层的能力需求
* 推动生成式UI相关标准化
* 明确安全护栏规范
* 构建更通用的DSL规范
* 研究多端统一渲染框架

---

### 3. 祖明（百度）

介绍了百度目前在生成式 UI 方向的相关工作。整体来看，实践路径与前面两位嘉宾分享的内容思路较为相似。

自2023年初开始探索AI应用以来，百度也是持续基于Markdown进行了各种扩展，以支持在对话的产品形态下，支持更丰富和强大的组件。同时，在智能体生态建设过程中，为了降低开发者接入成本的角度，也通过定义JSON DSL 的方式，提供UI布局与交互的能力。通过过去几年不断的迭代，逐步形成了一套相对成熟的解决方案。

去年年底，还将过去几年的技术积累进行系统化整合，包括协议、渲染引擎以及组件库等核心能力，对外进行了开源 👉 [https://github.com/baidu/cosui/](https://github.com/baidu/cosui/)

近期的重点研究方向，是探索如何利用大模型直接生成代码，在搜索场景下提供更多更丰富的交互应用。在这一过程中，也遇到了和上面嘉宾提到的一些共性问题，因此也希望后续能够与业界进一步交流，共同推动相关技术的发展与落地。

---
## 开放讨论环节

### Q1: 在AI聊天场景里，大模型生成UI界面的加载速度还重要吗？

**王佐：**  
在传统移动端技术发展过程中，经历了“原生→Web→跨端技术栈”的演进路径。跨端技术的核心目标，是在保持跨平台优势的同时，尽可能接近原生应用的性能和加载速度。之所以出现跨端技术方案，本质上是因为用户对Web页面“加载慢”的体验普遍不满意。

但在当前的AI对话和生成式应用场景中，用户心智已经发生了一定变化：在传统页面场景下，用户默认期望“点击即响应”，对速度非常敏感；而在AI聊天场景中，用户更倾向于把系统视为一个“有思考能力的智能体”，因此对响应速度具备更高的容忍度和耐心。

在生成式UI场景中，如果界面内容是通过Web技术动态加载和生成的，那么其加载速度的快慢，是否仍然像传统应用一样对用户体验构成关键影响？换言之，用户是否会因为“AI需要思考”的心理预期，而降低对即时性能的要求？希望了解各厂商在实际产品设计中，对这一问题的看法和需求定位。

**祖明：**  
在百度搜索场景下，目前我们对于性能的要求还是相对比较高的，这也是我们目前遇到的一个比较大的业务场景约束和挑战。

**冉若曦：**  
我简单补充一下关于性能方面的一些想法。后续相关工作我们也会继续推进，并在合适的时机与大家进一步交流和探讨。

刚才在听春辉的分享时，我注意到他提到的一个观点——现阶段生成式UI存在的“不可能三角”。这让我也产生了一些思考。当前在使用大模型的过程中，无论是通过API调用、在本地部署模型，还是通过Web应用来使用大模型，大家似乎对模型生成内容的响应时间都具有较高的容忍度。

从目前阶段来看，用户普遍能够接受大模型“需要思考时间”的特点，对实时性要求相对宽松。但从更长远的角度来看，我并不确定这种容忍度是否会一直持续。回顾Web技术的发展历程可以看到：在早期阶段，用户对网页加载速度的容忍度也很高，甚至等待一分钟都可以接受；而随着技术进步和体验提升，如今用户对响应时间的要求已经显著提高。

因此我在思考，在大模型和AI应用逐渐普及的过程中，是否也会出现类似的趋势——用户对性能的期望会逐步提升，对延迟的容忍度会逐渐降低。

在当前技术阶段，我们可能确实需要面对类似的“不可能三角”问题：在性能、灵活性和体验之间如何取得平衡。如何在不断优化性能的过程中，找到一个合理的平衡点，我认为这是一个非常值得探讨的议题。无论是在W3C内部，还是在整个产业界，都有必要围绕这一问题展开更深入的讨论。

**莫春辉：**  
我想从性能指标的角度谈一下生成式UI与大模型之间的关系。

在大模型领域，有两个非常重要的性能指标：TTFT（Time To First Token）和TPOT（Time Per Output Token）。这两个指标已经成为衡量大模型性能的关键标准。我在思考，对于生成式UI来说，是否也应该建立类似的一套衡量体系，用来评估用户体验层面的性能表现。

目前一个可以考虑的思路，是参考大模型已经相对成熟的指标体系，把它们作为生成式UI指标设计的输入项。例如，在大模型生成过程中，即便最终结果还没有完全输出，但只要能尽早给用户一些反馈——无论是思维链的展示，还是部分内容的逐步呈现——本身就是一种有效的“响应”。关键在于：用户从点击提交到看到第一个有效反馈之间的等待时间，以及用户对这一等待时间的容忍度。

在传统静态UI时代，我们通常遵循“三秒原则”，即用户对超过三秒的无响应难以接受，否则会造成大量流失。但在生成式UI场景下，这个标准显然不再适用。大模型的计算过程天然需要时间，因此用户的心理预期和容忍度也会更高。不过，如果完全没有反馈，让用户等待一两分钟的空白界面，同样是不可接受的。

因此，我认为接下来需要重点探讨的是生成式UI的性能指标究竟应该如何定义？

是否可以借鉴大模型的TTFT思路，把“首个可见反馈出现的时间”作为一个核心衡量标准？

进一步来看，对于UI场景，我们还需要更细粒度的指标。例如：

- 第一个界面元素出现的时间；
- 后续内容逐步渲染的节奏；
- 每个文本字符或每个UI组件模块的输出间隔。

无论是文字内容的逐步呈现，还是图形化界面中各个组件的渐进式加载，本质上都类似于token的流式输出。我们完全可以把“每个可视化部件的输出时间”作为衡量生成式UI性能的一个重要维度。

总体来说，我的建议是：参考大模型的TTFT和token输出节奏，建立一套适用于生成式UI的量化性能指标体系，用来评估“首界面展示时间”和“后续UI元素逐步呈现的效率”。这样才能为行业提供一个可量化、可评估的统一标准，也更有助于优化真实用户体验。

---

### Q2: 如何通过标准合作优化平台与生态

**王佐：**  
我再补充一个想法。刚才几位分享者都提到了“私有标准”的问题，这也是我一直比较关注和思考的一个点。

从我的理解来看，无论是面向服务提供商，还是面向大模型平台厂商、数字环境厂商，当前各方都在基于自身需求制定各自的UI描述规范。对于这种现象，我一直抱有一个疑问：  
我们是否有必要，也是否有可能，推动生成式UI的相关标准走向统一？

现在的趋势是，大模型逐渐成为服务的分发平台。当它完成服务分发时，最终一定会向用户呈现一个交互界面，而这个界面往往是由模型自动生成的。而且在实际场景中，这个过程不仅仅是单一模型完成的，还可能涉及多个服务商和多个AI Agent的协作，最终共同生成一个结果界面。

在这种情况下，如果每个模型、每个平台都各自定义一套私有的UI描述方式，门槛虽然看似很低，但从长远来看对整个生态并不友好。举个例子，如果市场上有十个大模型厂商，而每家都采用不同的界面描述标准，那么作为应用开发者或服务商，就需要分别去适配十套不同的协议和解析方式。这无疑会大幅增加集成成本，也不利于技术生态的健康发展。

因此，我想表达的核心观点是：在生成式UI的描述层面——无论是基于HTML/CSS，还是更抽象的DSL形式——我们是否能够先达成一个基本共识：尽可能推动这一层的标准化和统一化？

如果能够在这一点上形成共识，让不同模型和平台都遵循相对一致的描述规范，那么对开发者、服务商以及整个产业生态都会更加有利，也能更好地促进生成式UI技术的长期发展。

**胡春明：**  
我简单分享两个观点。  第一，我认为在最终UI呈现这一层，肯定还是需要一个标准。前面大家都提到了“子集”的概念，从当前的技术形态来看，无论生成式UI以什么形式输出，最终都离不开一个运行时环境去渲染。哪怕今天大模型只输出Markdown，也仍然需要渲染器去解析和展示它。如果交互更复杂，就需要更丰富的API支持，最终还是要交给一个类似View的运行时层来完成展示和交互。

所以从架构上看，这里天然存在一个分层：

- 一层是大模型生成某种受约束的DSL；
- 另一层是从轻量到复杂的渲染运行时，用来解析这个DSL并实现交互。

无论我们是否主观上喜欢，这种“生成层+运行时层”的分层结构实际上是客观存在的。

第二个观点是关于跨厂商统一的问题。理论上，每个厂商可以只为自己的模型定义一套DSL，只要自家运行时能解析就够了。但如果完全不做标准化，就会导致大量重复造轮子：不同厂商都要各自开发和维护类似的运行时和解析机制，成本很高，也不利于生态发展。

如果能够对这一层做一定程度的标准化，或者至少定义若干能力层次的“子集规范”，就可以让内容供给和运行时解耦，这对整个产业是有意义的。

另外还有一个现实需求：未来可能会有多个大模型和多个服务方共同参与生成一个界面。例如用户通过某个模型访问携程或航空公司的服务，从品牌方角度看，他们希望界面风格能够符合自身的品牌一致性。如果能提供类似template的中间层机制，让生成式UI在既定模板基础上填充内容，也许可以更好地满足这种诉求。

综合来看，如果这些需求确实普遍存在，那么在中间层定义一些跨厂商的规范，就不仅仅是技术上的优化，而是具有实际产业价值的方向。这是我的一些观察，供大家参考。

---

### Q3: UI组件

**莫春辉：**  
其实这个话题我们之前也讨论过。对于生成式UI来说，一个非常核心的问题就是UI组件的收敛性。既然是UI，就必然涉及组件，而目前各个厂商在开发应用时，所使用的组件库差异非常大，几乎不可能要求所有厂商统一使用同一套组件库来实现界面展示。

如果我们希望构建一个生成式UI的渲染引擎，让大模型输出的内容通过运行时进行渲染，就必然会遇到一个现实问题：这个渲染引擎到底应该基于什么样的组件体系？

每个厂商、每个业务场景都有自己的一套组件实现，很难在框架层面强行统一。因此，无论是框架层还是组件库层，其实都很难做到完全收敛。在这种情况下，如果要讨论一个能够被广泛接受的标准化运行时环境，我认为目前唯一真正具备收敛可能性的方向，还是基于Web技术——这也是W3C的核心领域。

基于这个思路，我们内部也在做一些探索。现在的做法是：允许大模型输出描述组件使用方式的DSL；支持不同技术栈（例如React、Vue、Web Components等）；在渲染之前，将不同技术栈的组件统一转换为Web标准组件进行处理。

我们在这方面也参考了一些现有实践，比如Google的A2UI协议。通过研究可以发现，Google也在尝试做类似的收敛：它的示例中既支持Angular组件，也支持Web Components，并计划支持更多框架。从这个角度来看，在底层通过Web Components实现统一，是一个相对可行的技术路径。

我们的思路也是类似的：在把组件传递给渲染引擎之前，先统一转换为Web Components。由于相关技术已经比较成熟，这种转换本身难度并不大。这样一来，在真正进行渲染时，渲染引擎只需要处理标准的Web组件，而不需要关心上层使用的是哪种具体框架或组件库，就可以在浏览器环境中实现一致性的展示效果。

不过需要注意的是，如果DSL协议中直接包含了某个具体组件库的使用方式，那么这种协议本身是很难成为通用标准的。更合理的做法是类似A2UI的思路：标准层面不规定组件的具体格式，而是定义一种机制，让开发者事先向大模型声明“可用组件集合及其参数能力”。大模型只需要基于这些能力去生成UI，而不需要关心组件的具体实现细节。

我认为，在这一层面上是可以实现一定程度的收敛和标准化的，这可能也是我们后续可以重点推进的方向。

---

### Q4: Web子集

**吴小倩：**  
介绍W3C MiniApps工作组、W3C高性能Web应用社区组、WebView社区组、IWA社区与PWA Widget社区的[联合讨论](https://www.w3.org/community/high-perf-baseline/2025/12/17/tpac-2025/)。

**薛富侨：**  
在GitHub上的讨论里，我也写了一些自己的想法。结合刚才各位专家的分享，我认为生成式UI的发展有两个主要方向：

- 直接生成Web页面，即生成HTML/CSS/JS代码；
- 基于组件库生成受限的卡片形式，例如用JS、XML等定义组件，然后通过组件库渲染。

我认为这两个方向并非非此即彼，可以同时考虑。

对于直接生成Web的方向，它的灵活性和上限非常高，可以生成丰富的界面，但也带来一些问题，尤其是安全性和通信问题。为了兼顾灵活性与安全性，我之前考虑的方案是：

- 建立一个受限子集的HTML/CSS/JS，并配套渲染指南；
- 类似小程序的运行时环境，规定允许使用的元素和属性，同时排除高风险或高资源消耗的功能，例如禁止使用`<script>`标签、禁止加载过多外部资源；
- 通过沙箱规则来保证安全。

另一方面，我们也可以考虑制定标准化的DSL：

- 让模型或服务商生成的界面能够在不同环境中可靠渲染；
- 对训练新模型时，模型能够学习DSL语法，更高效地产生界面；
- 具体DSL的语法和设计需要在实践中不断探索和调整。

另外，针对组件库的问题，W3C的[Open UI社区组](https://www.w3.org/groups/cg/open-ui/)正在做UI组件标准化的工作，我们可以关注并参考其思路。

总体来说，我认为未来可以从直接Web和DSL标准化两条路径同时探索，为生成式UI的安全性、可控性和跨平台渲染提供可行方案。

---

### Q5: 测试与验证

**王佐：**  
关于生成式UI的测试与验证，我有几点思考：

传统Web开发中，人会在上线前进行测试，但生成式UI由模型生成，尤其是复杂界面，已经不可能完全依赖人工验证。

因此，需要建立专门的测试流程或基础设施，可能在端上部署虚拟环境，让模型生成的界面先在测试环境中自动验证其正确性和可靠性。

有实践案例显示，一些公司在服务端或虚拟环境中，用模型自动生成测试用例并运行，验证生成产物的正确性，然后再交付给用户。

总结来说，生成式UI的可靠性验证应更多依赖自动化测试和虚拟化环境，而不是传统的人工测试，这是保证用户看到内容可靠的重要手段。

**冉若曦：**  
关于生成式UI的无障碍（Accessibility）和测试，我有以下几点想法：

- UI与无障碍高度相关，生成式UI的内容如果不符合无障碍标准，可能会带来合规风险，例如在欧洲和美国可能面临产品下架等问题；
- 现有的一些自动化无障碍测试工具尚无法覆盖所有标准，因此生成式UI的无障碍验证仍存在空白；
- W3C可以借鉴WPT（[Web Platform Tests](https://github.com/web-platform-tests/wpt)）平台的经验，考虑开发一个开源的测试平台或工具，用于对生成式UI进行自动化验证，包括无障碍测试；
- 目标是建立一套可共享的开源方法和平台，让不同厂商和开发者能够统一测试生成式UI的无障碍和其他关键质量指标。

**薛富侨：**  
关于生成式UI的自动化测试与验证，我认为可以考虑以下方向：

- W3C目前已有浏览器测试与工具工作组，其中包含WebDriver协议，可以作为参考或基础；
- 可以探索自动化生成、运行和评估生成UI的方法，例如：
  - 自动截图或抓取生成的UI；
  - 将生成的UI与用户意图进行对比验证；
  - 如果验证未通过，可以让系统自动进行修复尝试，直到符合验证标准为止。

这些方法可以为生成式UI的可靠性和用户体验提供可量化的测试手段，也可作为后续标准化和工具化的基础。

---

## 结论与下一步计划

Generative UI社区组于本次会后成立，并计划围绕以下领域展开进一步探索：

- **评估与性能：** 探索如何在Web环境中界定与评估Generative UI的延迟、响应及输出质量，并识别W3C现有标准化工作中的空白。
- **验证与测试：** 研究针对Generative UI的验证与测试方法，这些方法应超越传统的端到端测试，可包含结构化测试用例与参考实现的应用。
- **中间表示：** 探究轻量级、跨厂商的中间表示或协议对Generative UI的潜在价值，以期提升其互操作性与模型兼容性。
- **与Web平台对齐：** 审视Generative UI系统是否能受益于一个轻量的Web技术子集，并需与现有的Web原则保持一致。

欢迎加入[Generative UI社区组](https://www.w3.org/groups/cg/gen-ui/)并参与相关讨论。
